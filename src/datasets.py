# -*- coding: utf-8 -*-
"""datasets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nqegiw5oWPRfsqhQKLUuNiPSQ2srnvMh
"""

import torch
import numpy as np
import cv2
import os

import torch
from torch.utils.data import Dataset, DataLoader

# SOURCES:
# - https://pytorch.org/tutorials/beginner/basics/data_tutorial.html
# - https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html
# - https://pytorch.org/docs/stable/tensors.html
# - https://en.wikipedia.org/wiki/YCbCr

class SRCNN_Dataset(Dataset):
  def __init__(self, lr_dir, hr_dir, ):
    # Set LR and HR paths
    self.lr_dir = lr_dir
    self.hr_dir = hr_dir

    # Get a list of images in LR and HR path, then sort to ensure LR images correspond to HR images
    self.lr_files = sorted([f for f in os.listdir(lr_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])
    self.hr_files = sorted([f for f in os.listdir(hr_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])

  def __getitem__(self, index):
    """
    Function to get the Y channel in YCbCr color space
    """
    # Get the LR and HR image path
    lr_file = os.path.join(self.lr_path, self.lr_files[index])
    hr_file = os.path.join(self.hr_path, self.label_files[index])

    # Read each LR and HR image
    lr_image = cv2.imread(lr_file)
    hr_image = cv2.imread(hr_file)

    # Convert to YCbCr color space
    lr_image_ycbcr = cv2.cvtColor(lr_image, cv2.COLOR_BGR2YCrCb)
    hr_image_ycbcr = cv2.cvtColor(hr_image, cv2.COLOR_BGR2YCrCb)

    # Then get the Y channel and normalize it for tensor
    lr_image_y = lr_image_ycbcr[:, :, 0].astype(np.float64) / 255.0
    hr_image_y = hr_image_ycbcr[:, :, 0].astype(np.float64) / 255.0

    # Expand the dimension so its CHW, not just HW
    lr_image_y = np.expand_dims(lr_image_y, axis=0)
    hr_image_y = np.expand_dims(hr_image_y, axis=0)

    # Convert to PyTorch tensors
    return(
        torch.tensor(lr_image_y, dtype=torch.float)
        torch.tensor(hr_image_y, dtype=torch.float)
    )

